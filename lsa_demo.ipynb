{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of SVD: Latent Semantic Analysis\n",
    "\n",
    "Strategy: given a corpus of articles, we want to create a term-document-type of matrix, for which we can do SVD analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse.csr as csr\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.base import clone\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Representing a corpus of documents as a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words matrix\n",
    "\n",
    "Following the <a href=\"http://scikit-learn.org/stable/modules/feature_extraction.html\">Sklearn Feature-extraction documentation page</a>\n",
    "\n",
    "- we start with a given **corpus** of $D$ documents.\n",
    "- we preprocess each document and convert it into a list of terms (features)\n",
    "    - by lowercasing first\n",
    "    - accepting only word patterns (defined via regex)\n",
    "- then we form the $CV$ Count-Vectorizer term-frequency matrix defined as:\n",
    "\n",
    "$$\n",
    "\\text{tf}(t, d)\\equiv{CF}_{d,t} = \\text{# times term }t\\text{ occurs in document }d\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', #default\n",
    "#     token_pattern='(?u)\\\\b[a-zA-Z]\\\\w+\\\\b',    \n",
    ")\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abra',\n",
       " 'and',\n",
       " 'cadabra',\n",
       " 'document',\n",
       " 'first',\n",
       " 'is',\n",
       " 'one',\n",
       " 'second',\n",
       " 'the',\n",
       " 'third',\n",
       " 'this']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the the first first document abra.',\n",
    "    'This is the second second document cadabra.',\n",
    "    'And the third one 3.',\n",
    "    'Is this the first document 4?',\n",
    "]\n",
    "X_corpus_docterm = vectorizer.fit_transform(corpus)\n",
    "# note the effect of modifying the token_pattern above....\n",
    "features = vectorizer.get_feature_names() \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our document-term matrix CV:\n",
    "CV = X_corpus_docterm.toarray()\n",
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'the'] [1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<1x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2 stored elements in COOrdinate format>,\n",
       " array([[0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doc2vec(doc, orig_vectorizer, debug=False):\n",
    "    # We can represent any new document in terms of our previous model\n",
    "    doc_vectorizer = clone(orig_vectorizer)\n",
    "    doc_corpus = [doc]\n",
    "    X_docterm = doc_vectorizer.fit_transform(doc_corpus)\n",
    "    doc_features = doc_vectorizer.get_feature_names()\n",
    "    doc_counts = X_docterm.toarray()[0]\n",
    "    if debug:\n",
    "        print(doc_features, doc_counts)\n",
    "    nonzero_idx = [\n",
    "        orig_vectorizer.vocabulary_.get(feature) for feature in doc_features]\n",
    "    vec = sparse.coo_matrix(\n",
    "        (doc_counts, (np.zeros_like(doc_counts), nonzero_idx)),\n",
    "        shape = (1, CV.shape[1]))\n",
    "    return vec, doc_features, doc_counts\n",
    "\n",
    "v,_,_ = doc2vec('The the first', vectorizer, debug=True)\n",
    "v, v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['This is the the first first document abra.',\n",
       "  'This is the second second document cadabra.',\n",
       "  'And the third one 3.',\n",
       "  'Is this the first document 4?'],\n",
       " array(['abra', 'and', 'cadabra', 'document', 'first', 'is', 'one',\n",
       "        'second', 'the', 'third', 'this'],\n",
       "       dtype='<U8'),\n",
       " array([[1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1],\n",
       "        [0, 0, 1, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "        [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To recap\n",
    "corpus, np.array(features), X_corpus_docterm.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Term-Document matrix:\n",
    "\n",
    "- The document vectors are not normalized \n",
    "    - can't really compare documents\n",
    "- The document vectors contain many common english words containing no information\n",
    "    - ideally we want to remove those, e.g. 'the', 'is', etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: TF-IDF vectorizer (see <a href=http://scikit-learn.org/stable/modules/feature_extraction.html> The TF-idf section in the Scikit-Learn feature extraction manual</a>)\n",
    "\n",
    "Instead, let's consider the following matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{tf-idf}(t,d) &\\equiv{\\text{tf}}(t,d)\\times\\text{idf}(t)\\\\\n",
    "\\text{idf}(t)&\\equiv\\log\\frac{1+n_d}{1+\\text{df}(d,t)} + 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "- $\\text{df}(d,t)$ is the number of documents containing feature $t$\n",
    "- the rows of the tf-idf matrix are normalized to have unit norm (either $L_1$ or $L_2$)\n",
    "    - this way we can compare documents by the norm of their doc2vec overlaps\n",
    "    \n",
    "Let's see this in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abra', 'cadabra', 'document', 'second']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    norm='l2',\n",
    "    use_idf=True)\n",
    "\n",
    "X_corpus_tfidf=vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Note that only 2 vectors survive the transformation\n",
    "vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84292635,  0.        ,  0.53802897,  0.        ],\n",
       "       [ 0.        ,  0.43003652,  0.27448674,  0.86007303],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_corpus_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71052483,  0.        ,  0.28947517,  0.        ],\n",
       "       [ 0.        ,  0.18493141,  0.07534297,  0.73972562],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the no-zero rows are all normalized to 1\n",
    "X_corpus_tfidf.toarray() ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abra'] [ 1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<1x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 1 stored elements in COOrdinate format>,\n",
       " array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v,_,_ = doc2vec('The the first abra', vectorizer, debug=True)\n",
    "v, v.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Latent Semantic Analysis\n",
    "\n",
    "## Or Truncated SVD on the TF-IDF matrix\n",
    "\n",
    "**The Following code is based on <a href=\"http://scikit-learn.org/stable/auto_examples/applications/plot_out_of_core_classification.html\">Scikit-Learn's Reuters Dataset TF-IDF + K-NN classification example</a> along with <a href=\"http://mccormickml.com/2016/03/25/lsa-for-text-classification-tutorial/\">Chris McCormic's LSA tutorial</a> and his <a href=\"https://github.com/chrisjmccormick/LSA_Classification\">github page</a>. The original Reuter's 21578 dataset is part of the <a href=\"http://archive.ics.uci.edu/ml/machine-learning-databases\">UCI-ML</a> repository and can be found <a href=\"http://archive.ics.uci.edu/ml/machine-learning-databases/reuters21578-mld/reuters21578.tar.gz\">here</a>. However, in this demo we are using the already <a href=\"https://github.com/chrisjmccormick/LSA_Classification/tree/master/data\">pre-processed</a> version in Chris McCormic's github page**\n",
    "\n",
    "### Let's look at some real data - the Reuters Articles Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train docs: 4743 Number of test docs: 4858\n",
      "\n",
      "train labels: [['cocoa', 'el-salvador', 'usa', 'uruguay'], ['usa'], ['usa'], ['usa', 'brazil']]\n",
      "\n",
      "This is how a sample train article looks like:\n",
      "\n",
      " BAHIA COCOA REVIEW\n",
      "\n",
      "Showers continued throughout the week in the Bahia cocoa zone, alleviating the drought since early January and improving prospects for the coming temporao, although normal humidity levels have not been restored, Comissaria Smith said in its weekly review. The dry period means the temporao will be late this year. Arrivals for the week ended February 22 were 155,221 bags of 60 kilos making a cumulative total for the season of 5.93 mln against 5.81 at the same stage last year. A\n"
     ]
    }
   ],
   "source": [
    "fname = \"raw_text_dataset.pickle\"\n",
    "filepath = os.getcwd() + '/' + fname\n",
    "raw_text_dataset = pickle.load(open(filepath, \"rb\"))\n",
    "X_train_raw = raw_text_dataset[0]\n",
    "y_train_labels = raw_text_dataset[1] \n",
    "X_test_raw = raw_text_dataset[2]\n",
    "y_test_labels = raw_text_dataset[3]\n",
    "\n",
    "print('Number of train docs:', len(X_train_raw), \n",
    "      'Number of test docs:', len(X_test_raw))\n",
    "print('\\ntrain labels:', y_train_labels[:4])\n",
    "print('\\nThis is how a sample train article looks like:\\n\\n', \n",
    "      X_train_raw[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF vectorizer step:\n",
    "The TfidfVectorizer below does the following:\n",
    "- TF Step\n",
    "    - Strips out “stop words”, e.g. frequently occuring english words\n",
    "    - Filters out terms that occur in more than half of the docs\n",
    "    (max_df=0.5)\n",
    "    - Filters out terms that occur in only one document (min_df=2).\n",
    "    - Selects the 10,000 most frequently occuring words in the corpus.\n",
    "    - Normalizes the vector to account for the effect of document\n",
    "    length on the tf-idf values. Here we use l1 norm which normalized\n",
    "    by the document length\n",
    "- IDF Step\n",
    "    - Nomalize each \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4743, 10000)\n",
      "first 10 features: ['00', '000', '0000', '001', '002', '003', '004', '005', '006', '008']\n",
      "last 10 features: ['zimbabwe', 'zinc', 'zoete', 'zone', 'zones', 'zorinsky', 'zortman', 'zuckerman', 'zurich', 'zy']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, # ignore terms which occur in more than half of the documents\n",
    "    max_features=10000,\n",
    "    min_df=2, # ignore terms which occur in less than 2 documents\n",
    "    stop_words='english',\n",
    "    norm='l2',\n",
    "    use_idf=True, \n",
    "    analyzer='word',\n",
    "    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
    "#     token_pattern = '(?u)\\\\b[a-zA-Z]\\\\w+\\\\b'\n",
    "    )\n",
    "\n",
    "# note how changing the token_pattern changes\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_raw)\n",
    "print(X_train_tfidf.shape)\n",
    "print('first 10 features:', vectorizer.get_feature_names()[:10])\n",
    "print('last 10 features:', vectorizer.get_feature_names()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19  documents found\n",
      "document  1 :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"TALKING POINT/AUTO SUPPLIER STOCKS\\n\\nThe 1987 outlook for U.S. auto sales is clouded by a decidedly mixed sales forecast, and analysts who follow the industry say it is also true for companies that sell parts and equipment to the major car and truck manufacturers. But while there are only four major U.S.-based automakers whose shares are traded on stock exchanges, there are thousands of big and small suppliers who sell a flood of original and replacement parts. Analysts who follow the parts industry say there are many opportunities for investors brought on by the auto industry's intensified competition and the large volume of production in North America planned by Japanese automakers. But assessing the supplier arena is far more complicated than for investors considering the stocks of the Detroit Big Three - General Motors Corp GM>, Ford Motor Co F> and Chrysler Corp C>. Despite widespread predictions that U.S. vehicle sales will decline about 10 pct from the record 1987 levels, Wall Street financial experts are still generally bullish on Ford and somewhat less so on Chrysler. And analysts remain largely neutral to bearish on GM, the industry giant whose earnings have been dropping along with its sales as it struggles to reorganize and shed its unprofitable parts-making businesses. more \""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at documents that contain the word 'cocoa'\n",
    "doc_idx = X_train_tfidf[\n",
    "    :, vectorizer.vocabulary_.get('bullish')].nonzero()[0].tolist()\n",
    "print(len(doc_idx), ' documents found')\n",
    "i = 1\n",
    "print('document ', i, ':')\n",
    "X_train_raw[doc_idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing dimensionality reduction using LSA\n",
      "  done in 4.397sec\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerforming dimensionality reduction using LSA\")\n",
    "t0 = time.time()\n",
    "\n",
    "# Project the tfidf vectors onto the first N principal components.\n",
    "# Though this is significantly fewer features than the original tfidf vector,\n",
    "# they are stronger features, and the accuracy is higher.\n",
    "svd = TruncatedSVD(\n",
    "    n_components=200,\n",
    "    random_state=42,\n",
    "    algorithm='arpack'\n",
    ")\n",
    "\n",
    "lsa = make_pipeline(\n",
    "    svd, \n",
    "#     Normalizer(copy=False) # try commenting this out. Do you get a better result?\n",
    ")\n",
    "\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "print(\"  done in %.3fsec\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Explained variance of the SVD step: 36%\n"
     ]
    }
   ],
   "source": [
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"  Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
    "\n",
    "\n",
    "# Now apply the transformations to the test data as well.\n",
    "X_test_tfidf = vectorizer.transform(X_test_raw)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's improve a K-nn classifier using LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Reuters dataset consists of ~100 categories. However, we are going to\n",
    "# simplify this to a binary classification problem. The 'positive class' will\n",
    "# be the articles related to \"acquisitions\" (or \"acq\" in the dataset). All\n",
    "# other articles will be negative.\n",
    "y_train = [\"acq\" in y for y in y_train_labels]\n",
    "y_test = [\"acq\" in y for y in y_test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying tfidf vectors...\n",
      "  (4471 / 4858) correct - 92.03%\n",
      "  done in 1.863sec\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassifying tfidf vectors...\")\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "# Build a k-NN classifier. Use k = 5 (majority wins), the cosine distance, \n",
    "# and brute-force calculation of distances.\n",
    "knn_tfidf = KNeighborsClassifier(n_neighbors=5, algorithm='brute', metric='cosine')\n",
    "knn_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Classify the test vectors.\n",
    "p = knn_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "# Measure accuracy\n",
    "numRight = 0;\n",
    "for i in range(0,len(p)):\n",
    "    if p[i] == y_test[i]:\n",
    "        numRight += 1\n",
    "\n",
    "print(\"  (%d / %d) correct - %.2f%%\" % (numRight, len(y_test), float(numRight) / float(len(y_test)) * 100.0))\n",
    "\n",
    "# Calculate the elapsed time (in seconds)\n",
    "elapsed = (time.time() - t0)\n",
    "print(\"  done in %.3fsec\" % elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying LSA vectors...\n",
      "  (4561 / 4858) correct - 93.89%\n",
      "    done in 1.086sec\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassifying LSA vectors...\")\n",
    "\n",
    "# Time this step.\n",
    "t0 = time.time()\n",
    "\n",
    "# Build a k-NN classifier. Use k = 5 (majority wins), the cosine distance, \n",
    "# and brute-force calculation of distances.\n",
    "knn_lsa = KNeighborsClassifier(n_neighbors=5, algorithm='brute', metric='cosine')\n",
    "knn_lsa.fit(X_train_lsa, y_train)\n",
    "\n",
    "# Classify the test vectors.\n",
    "p = knn_lsa.predict(X_test_lsa)\n",
    "\n",
    "# Measure accuracy\n",
    "numRight = 0;\n",
    "for i in range(0,len(p)):\n",
    "    if p[i] == y_test[i]:\n",
    "        numRight += 1\n",
    "\n",
    "print(\"  (%d / %d) correct - %.2f%%\" % (numRight, len(y_test), float(numRight) / float(len(y_test)) * 100.0))\n",
    "\n",
    "# Calculate the elapsed time (in seconds)\n",
    "elapsed = (time.time() - t0)    \n",
    "print(\"    done in %.3fsec\" % elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Probelm 1:\n",
    "- Download the Reuters data from Chris McCormick's github repo https://github.com/chrisjmccormick/LSA_Classification\n",
    "    - Make sure the code in this notebook runs against the raw_text_dataset.pickle in the github repo\n",
    "    - assume that the dataset PATH is in the same directory as where the notebook is so that our grader Yifei can run your notebook with his own copy of the dataset in the same folder\n",
    "    - also feel free to modify this current notebook so as to complete the rest of the problem below:\n",
    "    \n",
    "- Create a doc2vec(doc, tfidf_vectorizer) function corresponding to a TFIDF vec\n",
    "    - INPUTS: doc, tfidf_vectorizer\n",
    "        - doc - any string\n",
    "        - tfidf_vectorizer - a TfidfVectorizer instance\n",
    "    - OUTPUTS: vec, doc_features, doc_counts\n",
    "        - vec - a vector with $L_2$ norm of $1$\n",
    "        - doc_features - the features after tokenization and pre-processing\n",
    "        - doc_counts - the counts of each feature in this document\n",
    "    - note that you should not normalize by the inverse document frequency as there is just a single document\n",
    "- For each of the following doc strings, calculate their corresponding vectors\n",
    "    - doc1: \"The cocoa cadabra\"\n",
    "    - doc2: \"AAPL SE\"\n",
    "    - doc3: \"bullish stocks\"\n",
    "- Create a **recommend(vec, X_model, X_corpus)** function:\n",
    "    - which projects any document vector onto X_model\n",
    "        - here X_model = {X_train_tfidf, and X_train_lsa}\n",
    "    - and returns doc_vec, idx_top10, sim_top10, X_top10 as follows\n",
    "        - doc_vec - the (sparse) vector of similarity scores of vec and members of X_model. \n",
    "        This vector should be size (Dx1)\n",
    "        - idx_top10: the indices of the top-10 similarity scores\n",
    "        - sim_top10: the top-10 similarity scores\n",
    "        - X_top10: the top-10 corpus articles most similar to the input model\n",
    "    - what does your recommend() function ouput for the doc vectors in the previous exersise?\n",
    "        - Do you see an improvement of the LSA similarity recommendation relative to the TF-IDF similarity recommendation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
